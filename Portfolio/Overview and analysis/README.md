-------------------------------------------------- Glossery of the Data & Analytics ----------------------------------------------

## The process (ETL):

1. Checking the data's reliability: some datasets are trustworthy by proxy of their sources (such as the EU data center and the UK government open data project), but work is still necessary to insure that if the project will use only a subset of the data (due to size constraints for example) that the sample be representative of the population and free from bias.
2. Cleaning the data: Checking for duplicate entries, erros, misinputs and deleting them.
3. Defining and claculating the metrics: Each project has an attached word file within it's folder that defines each metric calculated, why is it of interest and what formula is used to obtain it.
4. Advanced data work: If macros were created as part of the project, or if a SQL expression optimisation process was undertaken, it will also be mentioned in the word file. With some projects this subprocess will not be truly necessary to obtain the results but will still be included just to showcase the skills associated with it.
5. Preparing a data Pipeline: As with most advanced data projects, a permanent data pipeline is necessary to keep the dashboard consistantly up-to-date. Although this is not really possible due to the static nature of our datasets/bases here, the groundwork can still be laid to showcase how this would work in the right data context. 
6. Writing the story: What do the metrics tell us? this is the part where I weave the metrics together to piece together the bigger picture in a clear and easy-to-understand narrative but also to unearth relationships that are not so obvious at first glance. This analysis is available in a word document within this folder here for each project.  (This is personally the most fun part of the process for me)
7. Visualising the story: Another skill that compliments the previous step is knowing how best to showcase each insight, making sure that its impact is fully absorbed and understood by the audience, while also combining all the insights visually, like pieces of a puzzle, to tell the full story we unearthed throughout this process.

==> All projects contain a "Project Log.md" file that chronologically captures all the steps taken and issues encountered, with plenty of details regarding the solutions and processes used, the techniques deployed ect.
-------------------------------------------------- General Info for all projects -------------------------------------------------
## Projects list

1. Full-stack EV Infrastructure Market Analysis project using Excel + Power BI (French to English)



## Tools & Software Used

- Power BI
- Tableau
- GitHub
- Visual Studio Code
- Excel
- DB Browser for SQLite

## Programming Languages & Libraries
- **Languages**: Python, SQL
- **Libraries**: xxx

## Infrastructure & Data Sources
### Publicly avaliable data sources:

- https://data.europa.eu/ (The official EU central repository for publicly available datasets)
    Topics: Economy, Energy, Environment, Transport, COVID-19
- www.data.gov.uk (UK's govemental open / publicly-avaialable datasets)
    Topics: Demographics, business stats, migration, crime, NHS, housing.
- www.Kaggle.com (general opensource datasets)
    Topics: Massive variety, too many to list here.
- https://data.worldbank.org/ (World bank's open data platfrom)
    Topics: Country-level indicators such as GDP, inflation, education, health, etc.
- www.imf.org and data-explorer.oecd.org.
    Topics: macroeconomic and Financial indicators and metrics.

### AI-generated databases:
- ChatGPT
- Claude
- Gemini


==> If there's a dataset you would like to have visualised that isn't already let me know and I'll be more than happy to do so for you.

<Note to self: maybe add powerpoint presentations here as well?>